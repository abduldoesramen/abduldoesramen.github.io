<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT"
      crossorigin="anonymous"
    />
    <title>COMP4920</title>
  </head>
  <body>
    <!-- Updated Navbar -->
    <nav class="navbar navbar-light sticky-top bg-light">
      <form class="container-fluid justify-content-start">
        <button
          type="button"
          onclick="location.href='https://abdulblog.me'"
          class="btn btn-light text-center btn-outline-success me-2"
        >
          About me
        </button>
        <button
          type="button"
          onclick="location.href='https://abdulblog.me/COMP3311.html'"
          class="btn btn-light text-center btn-outline-secondary me-2"
        >
          COMP3311
        </button>
        <button
          type="button"
          onclick="location.href='https://abdulblog.me/COMP4920.html'"
          class="btn btn-light text-center btn-outline-secondary me-2"
        >
          COMP4920
        </button>
      </form>
    </nav>
    <div class="alert alert-primary d-flex align-items-center" role="alert">
      I'll be adding notes to these tabs as the term progresses.
    </div>
    <h1 class="lead text-center display-2 text-muted">
      COMP4920 - Management and Ethics
    </h1>
    <!-- MD File CODE HERE -->
    <h1 id="week-1">Week 1</h1>
    <p>
      <em>Claim</em>: All humans are mortal (to be True) <em>Claim</em>:
      Socrates is a human (to be True) <em>Deduced</em>: Therefore, Socrates is
      mortal.
    </p>
    <p>
      Everything before &quot;therefore&quot; are <strong>claims</strong>.
      Everything after &quot;therefore&quot; is a <strong>conclusion</strong>.
      This style of proof is called an &quot;<strong>argument</strong>&quot;.
      Note: for this course: claims, statements and propositions can be used
      <em>interchangeably</em>.
    </p>
    <p>
      An ethical argument, is an argument in which the conclusion is a
      <strong>moral judgement/statement</strong>. A
      <strong>moral judgement</strong> is for example, &quot;burning kittens is
      wrong&quot;.
      <em
        >How can we know a moral argument (the reasons to believe moral/ethical
        claims) is right or wrong?</em
      >
      This course will be exploring the different, major theories behind this
      idea.
    </p>
    <h3 id="utilitarianism">Utilitarianism</h3>
    <ul>
      <li>
        <strong>Utilitarianism</strong> relies on making moral claims and
        ethical justifications based on imperical data.
      </li>
      <li>
        <strong>Kantian ethics</strong>, rely on pure axioms and does not rely
        on imperical data, i.e. pure computation, no external data.
      </li>
      <li>
        <strong>Virtue ethics</strong> is similar to data sets and machine
        learning
      </li>
    </ul>
    <p>
      Utilitarianism is a variety of consequentialism: which is a theory of
      <strong>normative</strong> (as opposed to meta) ethics.
      <strong>Consequentialism</strong> is a theory of ethics that focuses on
      cause, e.g. causing suffering <em>is</em> the wrong thing. Our actions do
      not have any intrinstic or inherent - moral values are the consequences of
      our actions that maximises happiness, minimise suffering. Utilitarianism
      schema are meant to apply universally all the time and is based on
      <strong>naturalism</strong> (alongside natural Sciences) that converts the
      bad and good to &quot;measurable&quot; suffering and happiness
      respectively. Cannot assign discrete values for borderline cases, but for
      vast majority of cases - we do know according to utilitarianism.
    </p>
    <p>
      Real explainations are given by the natural sciences, need to be
      falsifiable based on evidence (from the scientific method). Hence
      utilitarianism allows ethical claims to be measurable from observing
      happiness and suffering. Normative moral claims give instructions. For
      example, 10 commandments are moral instructions.
    </p>
    <p>Related to CompSci? Example: Trolley problem.</p>
    <pre><code><span class="hljs-keyword">One</span>-person <span class="hljs-keyword">in</span> bottom-rail, none <span class="hljs-keyword">on</span> the top-rail: <span class="hljs-keyword">save</span> the <span class="hljs-keyword">one</span>-person.
(Equally upset <span class="hljs-keyword">about</span> dying, equal happy <span class="hljs-keyword">about</span> living, qualitative the same).
<span class="hljs-keyword">One</span>-person <span class="hljs-keyword">in</span> bottom-rail, <span class="hljs-keyword">one</span> <span class="hljs-keyword">in</span> top-rail: <span class="hljs-keyword">Do</span> nothing? Flip a coin?
<span class="hljs-keyword">Two</span>-persons <span class="hljs-keyword">in</span> bottom-rail, <span class="hljs-keyword">one</span> <span class="hljs-keyword">in</span> top-rail: <span class="hljs-keyword">Do</span> nothing? <span class="hljs-string">"Play"</span> God?
Five-persons <span class="hljs-keyword">in</span> bottom-rail, <span class="hljs-keyword">one</span> <span class="hljs-keyword">in</span> top-rail: ?
Criminals? Innocent?: ?
Serial killer? Doctor?: ?
Good friend? Stranger?: ?
</code></pre>
    <p>
      <em>Utilitarianism</em>: reduces interpersonal and moral obligations to
      mere calculations of utility. Would we ever have strong civilisations?
      Bias to certain groups has been the cause of terrible things. However
      arguably - it has also been the very thing that has allowed our species to
      flourish if it had not shown preferential bias. Thus utilitariniasm:
      Suppose three-people bottom rail, one-people (dearest friend) on top rail.
      Pull the level and hit the friend.
    </p>
    <p>
      The runaway trolley is a train that is moving autonomously, however you
      can move it. All self-driving cars are runaway rail carts with navigation
      protocols based on your choices on whether the switch should be pulled.
      Though, you are <em>one</em> of the people on &quot;track&quot; because
      you are <em>on</em> the vehicle. What if it was programmed by a
      utilitarianism? I.e. kills <em>you</em> if it would possibly kill more
      than two people. Hence, what protocols should be in place when programming
      such autonomous vehicles?
    </p>
    <p>
      Humans = unpredictable. Vehicles = predictable. For a modern example:
      100,000 &quot;runaway trolleys&quot; - difficult to predict.
    </p>
    <p>
      Modern day, due to the idea of consequentialism - major goal is to reduce
      suffering.
    </p>

    <!-- JavaScript Bundle with Popper -->
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-u1OknCvxWvY5kfmNBILK2hRnQC3Pr17a+RTT6rIHI7NnikvbZlHgTPOOmMi466C8"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
