<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT"
      crossorigin="anonymous"
    />
    <!-- Google tag (gtag.js) -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-DVN1VDSLVF"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-DVN1VDSLVF");
    </script>
    <title>COMP4920</title>
  </head>
  <body>
    <!-- Updated Navbar -->
    <nav class="navbar navbar-light sticky-top bg-light">
      <form class="container-fluid justify-content-start">
        <button
          type="button"
          onclick="location.href='https://abdulblog.me'"
          class="btn btn-light text-center btn-outline-success me-2"
        >
          About me
        </button>
        <button
          type="button"
          onclick="location.href='https://abdulblog.me/COMP3311.html'"
          class="btn btn-light text-center btn-outline-secondary me-2"
        >
          COMP3311
        </button>
        <button
          type="button"
          onclick="location.href='https://abdulblog.me/COMP4920.html'"
          class="btn btn-light text-center btn-outline-secondary me-2"
        >
          COMP4920
        </button>
      </form>
    </nav>
    <div class="alert alert-primary d-flex align-items-center" role="alert">
      I'll be adding notes to these tabs as the term progresses.
    </div>
    <h1 class="lead text-center display-2 text-muted">
      COMP4920 - Management and Ethics
    </h1>
    <!-- MD File CODE HERE -->
    <h1 id="summary-of-week01-lecture">Summary of Week01 Lecture</h1>
    <br />
    <p>
      <em>Claim</em>: All humans are mortal (to be True) <em>Claim</em>:
      Socrates is a human (to be True) <em>Deduced</em>: Therefore, Socrates is
      mortal.
    </p>
    <p>
      Everything before &quot;therefore&quot; are <strong>claims</strong>.
      Everything after &quot;therefore&quot; is a <strong>conclusion</strong>.
      This style of proof is called an &quot;<strong>argument</strong>&quot;.
      Note: for this course: claims, statements and propositions can be used
      <em>interchangeably</em>.
    </p>
    <p>
      An ethical argument, is an argument in which the conclusion is a
      <strong>moral judgement/statement</strong>. A
      <strong>moral judgement</strong> is for example, &quot;burning kittens is
      wrong&quot;.
      <em
        >How can we know a moral argument (the reasons to believe moral/ethical
        claims) is right or wrong?</em
      >
      This course will be exploring the different, major theories behind this
      idea.
    </p>
    <h3 id="utilitarianism">Utilitarianism</h3>
    <ul>
      <li>
        <strong>Utilitarianism</strong> relies on making moral claims and
        ethical justifications based on imperical data.
      </li>
      <li>
        <strong>Kantian ethics</strong>, rely on pure axioms and does not rely
        on imperical data, i.e. pure computation, no external data.
      </li>
      <li>
        <strong>Virtue ethics</strong> is similar to data sets and machine
        learning
      </li>
    </ul>
    <p>
      Utilitarianism is a variety of consequentialism: which is a theory of
      <strong>normative</strong> (as opposed to meta) ethics.
      <strong>Consequentialism</strong> is a theory of ethics that focuses on
      cause, e.g. causing suffering <em>is</em> the wrong thing. Our actions do
      not have any intrinstic or inherent - moral values are the consequences of
      our actions that maximises happiness, minimise suffering. Utilitarianism
      schema are meant to apply universally all the time and is based on
      <strong>naturalism</strong> (alongside natural Sciences) that converts the
      bad and good to &quot;measurable&quot; suffering and happiness
      respectively. Cannot assign discrete values for borderline cases, but for
      vast majority of cases - we do know according to utilitarianism.
    </p>
    <p>
      Real explainations are given by the natural sciences, need to be
      falsifiable based on evidence (from the scientific method). Hence
      utilitarianism allows ethical claims to be measurable from observing
      happiness and suffering. Normative moral claims give instructions. For
      example, 10 commandments are moral instructions.
    </p>
    <p>Related to CompSci? Example: Trolley problem.</p>
    <pre><code><span class="hljs-keyword">One</span>-person <span class="hljs-keyword">in</span> bottom-rail, none <span class="hljs-keyword">on</span> the top-rail: <span class="hljs-keyword">save</span> the <span class="hljs-keyword">one</span>-person.
    (Equally upset <span class="hljs-keyword">about</span> dying, equal happy <span class="hljs-keyword">about</span> living, qualitative the same).
    <span class="hljs-keyword">One</span>-person <span class="hljs-keyword">in</span> bottom-rail, <span class="hljs-keyword">one</span> <span class="hljs-keyword">in</span> top-rail: <span class="hljs-keyword">Do</span> nothing? Flip a coin?
    <span class="hljs-keyword">Two</span>-persons <span class="hljs-keyword">in</span> bottom-rail, <span class="hljs-keyword">one</span> <span class="hljs-keyword">in</span> top-rail: <span class="hljs-keyword">Do</span> nothing? <span class="hljs-string">"Play"</span> God?
    Five-persons <span class="hljs-keyword">in</span> bottom-rail, <span class="hljs-keyword">one</span> <span class="hljs-keyword">in</span> top-rail: ?
    Criminals? Innocent?: ?
    Serial killer? Doctor?: ?
    Good friend? Stranger?: ?
    </code></pre>
    <p>
      <em>Utilitarianism</em>: reduces interpersonal and moral obligations to
      mere calculations of utility. Would we ever have strong civilisations?
      Bias to certain groups has been the cause of terrible things. However
      arguably - it has also been the very thing that has allowed our species to
      flourish if it had not shown preferential bias. Thus utilitariniasm:
      Suppose three-people bottom rail, one-people (dearest friend) on top rail.
      Pull the level and hit the friend.
    </p>
    <p>
      The runaway trolley is a train that is moving autonomously, however you
      can move it. All self-driving cars are runaway rail carts with navigation
      protocols based on your choices on whether the switch should be pulled.
      Though, you are <em>one</em> of the people on &quot;track&quot; because
      you are <em>on</em> the vehicle. What if it was programmed by a
      utilitarianism? I.e. kills <em>you</em> if it would possibly kill more
      than two people. Hence, what protocols should be in place when programming
      such autonomous vehicles?
    </p>
    <p>
      Humans = unpredictable. Vehicles = predictable. For a modern example:
      100,000 &quot;runaway trolleys&quot; - difficult to predict.
    </p>
    <p>
      Modern day, due to the idea of consequentialism - major goal is to reduce
      suffering.
    </p>
    <h1 id="summary-of-week02-lecture">Summary of Week02 Lecture</h1>
    <br />
    <h2 id="major-three-types-of-normatic-ethics-">
      Major three types of Normatic Ethics:
    </h2>
    <br />
    <h3 id="utilitarianism-consequentialism">
      Utilitarianism/Consequentialism
    </h3>
    <p>
      Ethics and moral judgement is achieved through the measurement
      (observation) and maximisation of utility (happiness over sadness) based
      on imperical evidence.
    </p>
    <h3 id="kantian-ethics">Kantian Ethics</h3>
    <p>
      Ethics and moral judgement come within through the exploration of
      categorical imperative (universality of certain laws) and does not rely on
      any imperical data.
    </p>
    <h3 id="virtue-ethics">Virtue Ethics</h3>
    <p>
      Ethics and moral judgement are derived through one&#39;s virtues and
      emotions through the comparison of a more virtuous individual.
    </p>
    <h3 id="tutorial-content">Tutorial Content</h3>
    <h4 id="exploring-deontology-">Exploring Deontology:</h4>
    <p>Util. &lt;---&gt; Deontology.</p>
    <p>Rule-based Util (within the middle).</p>
    <p>
      Deontology strongly prohibits certain classes of actions (that fails
      categorical imperative test).
    </p>
    <p>
      Negative duty (for example: Don&#39;t murder, your duty is to NOT murder
      -&gt; which is a perfect duty). (Passes imperative test): Permissable (for
      example: assisting the poor, upto you how much and when -&gt; which is an
      imperfect duty). NOT empirical, more axiomatic (conceptual) rather than
      observation, Kant analysis concepts/definitions and extrapolates from such
      concepts.
    </p>
    <p>Deontologist (rule-based theory):</p>
    <ul>
      <li>Kant is worried about excuses, and justifications of the wrong.</li>
      <li>
        Contemporary deontologist are worried about horrible actions being
        justified.
      </li>
    </ul>
    <p>
      Empirical = a posteriori (we can&#39;t do anything until post
      observation). Conceptual = a priori (don&#39;t need to observe anything,
      it is prior observation).
    </p>
    <p>Preliminary works:</p>
    <ul>
      <li>
        (Relevant)
        <em
          ><strong>Ground work</strong> (the beginning) to metaphysics of
          morals</em
        >, written in 1785. Based on the human capacity for free agency or
        autonomy (Auto - self, Nomis - law: give the law to ourselves), the
        human being is different from instinct-driven animals. Animals cannot
        make deep considerations of the future (lack long-term planning). Human
        beings can direct their lives according to reason. Capacity of autonomy
        Kant says is very important, humans have a duty (thinking of their
        actions and consequences) to animals but an animal cannot have a duty to
        humans. Kant argues that autonomy gives us dignity - that we can live
        our lives in the &quot;long-term&quot; and should only determined by
        ourselves - we do not need a third-party (any individual/government) to
        decide for us. Thus implies that humans are Ends (goal/outcome) in
        Themselves (you create your own end/future through rational planning
        <em>for</em> ourselves).
        <ol>
          <li>
            <strong>Maxim: general rule.</strong> (Example: give to the poor, do
            not steal, muder etc.) Could I desire this to be a universal law?
            For example: give to the poor, not self contradicting because no one
            WANTS to be poor. Borrowing money, but not giving back but now
            society will never trust anyone with their money.
            <strong
              >Maxim: it&#39;s okay to borrow money, but not give back</strong
            >.
          </li>
          <li>
            There would be times there would be exceptions to these universal
            rules for example: lying to save a life, this exemption case is now
            a universal case that will pass, allowing for exceptions. However
            now Deontology is moving towards the middle, where rule
            utilitarianism is near (similar to how introducing rules to
            Utilitarianism moves towards rule Util.).
          </li>
        </ol>
      </li>
      <li><em>Critique of practical reasoning</em>, written in 1788.</li>
    </ul>
    <p>Not <em>much</em> impact:</p>
    <ul>
      <li><em>Metaphysics of Morals</em>, written in 1797.</li>
    </ul>
    <h4 id="exploring-virtue-theory-">Exploring Virtue Theory:</h4>
    <p>Aristotle Virtue Theory:</p>
    <ul>
      <li>Virtue Theory is not based on decision-making.</li>
      <li>
        Majority of history is about the character/judgement of others and
        one&#39;s self.
      </li>
      <li>
        Aristotle wanted to create a well-rounded theory behind virtues, rather
        than the virtue of aggression and domination (single virtues) from Greek
        history. Rather wanting to produce a character in rationality, a
        character that is more well-rounded (multiple virtues).
      </li>
    </ul>
    <p>Contemporary Virtue Theory:</p>
    <ul>
      <li>
        Utilitarianism and Kantian ethics seems inhumane, for example: Harry S.
        Truman using utilitarianism to justify the bombing of Japan.
      </li>
      <li>
        General motivation: there is too much left (that make us human) out from
        the two theories, for example utilitarianism ruling out human intimate
        relationships when calculating utility (intimacy makes us human). The
        thought that a moral theory would throw out what a human is repulsive,
        essentially asking us to become in-human. There&#39;s no space for love,
        building relationship etc.
      </li>
      <li>
        Kant&#39;s theory is shown as very narrowly focused (universal laws,
        things you must NOT do).
      </li>
      <li>
        Other two theories are too technical and not based on human
        emotions/experience, such as love.
      </li>
    </ul>
    <p>Back to Aristotle Virtue Theory...</p>
    <ul>
      <li>
        Often Virtue Ethicists are critical of utilitarianism and deontologists.
      </li>
      <li>
        Often is associated on <em>how</em> we live our lives, and focuses on
        <em>becoming</em> virtuous.
      </li>
      <li>
        <p>
          Aristotle: You will never be able to generate a system of rules that
          will <em>always</em> be correct in every situation because moral
          problems are multidimensional.
        </p>
        <ol>
          <li>
            <p>
              However you <em>can</em> grow and <em>improve</em> yourself into a
              better human being that is more sensitive to moral dimensions of
              life (similar to how 10,000 hours is seen as an expert).
            </p>
          </li>
          <li>
            <p>
              Essentially, since the more you think, practice and engage about
              moral theory/virtue, you will become more sensitive to the moral
              dimensions of life.
            </p>
          </li>
          <li>
            <p>
              Develop a habit: surround a man with other virtuous men, for
              example: practising medicine around experts, learning about the
              theory behind driving but never stepping inside a vehicle.
            </p>
          </li>
        </ol>
      </li>
      <li>
        <p>
          Agent centered, but how does this relate to others? Others can benefit
          from one&#39;s virtuous activity, for example: mutual benefits from
          one&#39;s profession - especially in Information Technology (IT).
        </p>
      </li>
      <li>
        Virtues are <em>character traits</em>, for example: courage, patience,
        justice, fairness etc.
      </li>
      <li>
        <p>
          However Aristotle sees one character traits above others: prudence.
        </p>
        <ol>
          <li>
            <p>
              Phronesis (balancing the virtues), for example: Courage might get
              in the way of temperance. Virtues requires wisdom and regulation
              so they do not conflict and undermine one another.
            </p>
          </li>
          <li><p>Prudence is often known as practical wisdom.</p></li>
          <li>
            We accept virtues have the capacity of clashing. Prudence is the
            capacity to see on how to balance one&#39;s virtues, for example:
            giving a friend money when they are a drug addict.
          </li>
          <li>
            Prudencia takes wisdom (<em>insight</em>) to solve certain moral
            problems.
          </li>
        </ol>
      </li>
      <li>
        <p>
          <strong>Overall goal:</strong> Eudaimonia (good | spirt), be
          good-spirited and to do well, flourish.
        </p>
        <ol>
          <li>
            <p>Often translated to <em>flourishing</em>.</p>
          </li>
          <li>
            <p>
              For example: physically well, exercising their mind to be
              intelligent, thoughtful, accumalated enough things needed, have
              enough skill in their career, good relationship etc. Essentially
              doing well overall (flourishing across multidimensions).
            </p>
          </li>
        </ol>
      </li>
    </ul>
    <p>
      Artistotle has a functional concept of good (moral conception: saints,
      agents). However Artistotle believes that a thing is good if it serves its
      purpose <em>well</em>, for example: a knife is sharp and cuts well, a good
      race horse is that one that is fast. However a function of a human being
      is complicated, but is based on rationality and well-being but there is
      more to that. For example:
    </p>
    <pre><code>
        <span class="hljs-number">1</span>. Good doctor: Virtues <span class="hljs-keyword">of</span> a doctor.
        <span class="hljs-number">2</span>. Good soldier: Virtues <span class="hljs-keyword">of</span> a soldier.
        <span class="hljs-number">3</span>. Good journalist: Virtues <span class="hljs-keyword">of</span> a journalist.
    </code></pre>
    <p>
      Virtues are virtuous because they help us function. Emotions = Non
      Rational, however Aristotle seems to think that that our emotions have
      registered/seen something important, i.e. alert us.
    </p>
    <p>
      Virtues are caught between vices. For example, overly scared (cowardly),
      not scared enough (fool). Courage lies inside in the middle, i.e the
      <em>golden mean</em>. Either side leads to a failure to process this
      event. Aristotle: Virtues --&gt; Rationality of Passion --&gt; Golden
      Mean: between excess and deficiency.
    </p>

    <!-- WEEK 3 -->

    <h1 id="summary-of-week03-lecture">Summary of Week03 Lecture</h1>
    <h3 id="ethics-and-law">Ethics and Law</h3>
    <p>General message:</p>
    <pre><code>Legal != Ethical
Ethical != Legal
</code></pre>
    <p>
      For example, Legal != Ethical: Queensland laws can accuse Women of
      Witchcraft. Ethical != Legal: Jumping queues when waiting for your coffee.
      There is no strict one-to-one relationship between ethics and law, but
      your code of ethics/conduct is going to be shaped by our laws.
    </p>
    <p>
      Laws are generally supposed to be &quot;Action Guiding&quot;, for example:
      speeding - how fast you should be going. How does ethic guide your
      conduct? For example: ACM Code, breach of Code leads to expulsion ACM is
      important for reputation on your professional, for example: doctors
      associated with college of physicians.
    </p>
    <h3 id="values-principles-practices-and-purpose">
      Values, Principles, Practices and Purpose
    </h3>
    <p>
      Values = What we strive for, for example: value of Integrity,
      Transparency, etc. Principles = Shape conduct, for example: common
      principles in professional ethics: the harm minimisation principle, do no
      harm or justice: which equates to fairness, beneficious: which equates to
      social. Responsibility = For any principle or professional value, we are
      responsible and expectated to upheld them. Practices = How we follow and
      implement such principles or professionals in the real world. Purposes =
      How we unite Values and Principles, and why we list/follow such code of
      ethics/conduct.
    </p>
    <h3 id="is-technology-neutral-">Is Technology Neutral?</h3>
    <p>
      Perspective 1: (law 1) Technology is not good nor bad, and not neutral.
      For example: &quot;Guns don&#39;t kill people, people do&quot;,
      technically true but guns improve efficiency in killing others over a
      knife. &quot;Military technology&quot; originated day-to-day technology.
      &quot;Atomic Bomb&quot;: Purpose is to mass kill, indiscriminate including
      civilian targets, radioactive fallout, and is not precise in killing
      unlike an assault rifle, however is an atomic bomb good/bad/neutral? What
      exactly is the &quot;good&quot; of atomic bombs? Ending war, however more
      countries uphold it. Technology gives options, however certain options do
      not generally have a good outcome.
    </p>
    <p>
      (law 2) Necessity is the mother of innovation For example: privacy and
      confidentiality - users were not thinking of data security and privacy.
      United Nations: exploring breach of human rights via digital means, 2023
      summit occuring which will eventually influence Australian technoly-based
      law.
    </p>
    <p>
      <strong>Technology is a means with external ends</strong>: The use we put
      technology to ultimately depends on the user, for example: assault rifle
      has no say on how it is used. The <strong>way</strong> we use technology
      can be either good or bad.
    </p>
    <h3 id="history-of-technology-is-relevant">
      History of technology is relevant
    </h3>
    <p>Important inventions:</p>
    <p>
      Basic form of technology: writting/script - preserve information. Modern
      form of technology: smartphone - numbers/information conveyed through
      script.
    </p>
    <p>
      Printing press: Prior to the printing press, 95% of the population could
      not read, movement of oral to written-text based culture. Allowed mass
      printing and circulation of books and literature. Movement from the
      medieval world to the modern.
    </p>
    <p>
      Armour: military-based technology. Communication via telegram
      (revolutionary). Modern: smartphone, circuits, electricity.
    </p>
    <p>
      Marxist history is based on innovations from technology, society is based
      on such progression.
    </p>
    <h3 id="responsibility-from-the-creators-of-technology">
      Responsibility from the Creators of Technology
    </h3>
    <ul>
      <li>
        Researchers make decisions, and any decision made can have an ethical
        aspect behind it, for example: inventor of the Atomic Bomb.
      </li>
      <li>
        Think in terms of ethics, and the outcome when inventing
        products/services.
      </li>
      <li>
        What is the use potential of what I am attempting to invent. How could a
        malicious user of this product abuse it? What is the worst-case use?
      </li>
      <li>Invent some sort of buffer to prevent abuse of products/services.</li>
      <li>
        For example: Designers of the internet were not actively thinking of the
        sharing of abusive material when inventing the internet, the bitcoin was
        propped by the drug-market from the demand of having a decentralised and
        deregulated currency.
      </li>
    </ul>
    <h3 id="technology-opens-possibilities">Technology opens possibilities</h3>
    <ul>
      <li>Molly-Russell Case: exposure to suicide-type content.</li>
      <li>
        Young girl suffering depression using instagram to browse content
        related to self-harm and suicide, moving into areas where other
        depressed users were sharing content.
      </li>
      <li>
        Instagram: how to prevent? Social media is a vehicle to express
        themselves, e.g. happy people share joyful content, depressing/suicidal
        users will express themselves in suicidal ways.
      </li>
      <li>
        Reinforce suicidal thinking on their pysche, desires, life-style and
        health.
      </li>
      <li>
        Understand that there are a range of expressions that can be expressed
        on Social Media based on human nature.
      </li>
      <li>
        Result: Instagram executives acknowledges <em>some</em> responsibility
        to the Molly-Russell case.
      </li>
    </ul>
    <h3 id="code-of-conduct">Code of Conduct</h3>
    <p><strong>Foundation:</strong></p>
    <p>
      ACM Code: Developed through an ethical approach of principlism. 1979:
      Beauchump &amp; Childres - responding to the idea of high-moral theories
      are difficult for average people to employ. Thinking primarily in medical
      ethics, &quot;4 Principles of Bio-ethics&quot; sets the foundation of
      profession ethics and code of ethics/conduct in the 1980s onward.
    </p>
    <ul>
      <li>Beneficiance = do good.</li>
      <li>Non-Meleficence = do no harm.</li>
      <li>Autonomy = self direction</li>
      <li>Justice = fairness</li>
    </ul>
    <p>
      Attempted to take the main moral theories into principles. Specific nature
      of cases (ethical problems), we look at the case, think of moral
      implications/our intuitions, how we resolve other similar cases, and look
      at the principles. Bring these three things into equilibrium with each
      other and develop such principles further. Hence there is expanding
      principles. Each individual principle may develop (understand them better)
      and principles are added.
    </p>
    <p>
      1 section: Principles 2 section: Professional responsibilities 3 section:
      Professional leadership 4 section: potential expulsion if not following
      the ACM.
    </p>
    <h3 id="breakdown-of-principles-in-the-code">
      Breakdown of Principles in the Code
    </h3>
    <p>1.1</p>
    <ul>
      <li>Contribute to Wellbeing (util)</li>
      <li>
        <p>All People are Stakeholders (util)</p>
        <p>1.2</p>
      </li>
      <li><p>Negative consequences (util)</p></li>
      <li>Unjustified Harms (principle)</li>
      <li>
        <p>Well intentional acts that lead to harm (principle)</p>
        <p>1.3</p>
      </li>
      <li><p>Transparency (virtue)</p></li>
      <li>No false claims (Deontology)</li>
      <li>Honesty about Qualifications (virtue)</li>
      <li>
        <p>Conscious of Conflicts (virtue)</p>
        <p>1.4</p>
      </li>
      <li><p>Non-discrimination (Deontology)</p></li>
      <li>Fairness and allowing for redress (Deontological + Principilist)</li>
      <li>
        <p>
          Limiting inequality, i.e. Universal Access (virtue + Deontological)
        </p>
        <p>1.5</p>
      </li>
      <li><p>Intellectual property rights (Deontological)</p></li>
      <li>
        <p>Need for Sharing Work and Cooperation (virtue)</p>
        <p>1.6</p>
      </li>
      <li><p>Individual rights to privacy (Deontological)</p></li>
      <li>
        <p>Issue of Consent</p>
        <p>1.7</p>
      </li>
      <li><p>Entrusted (virtue, i.e. trustworthy)</p></li>
      <li>Honour confidentiality (virtue) (except if it breaks the law)</li>
    </ul>
    <p>
      <em>Court</em>: Duty to care, Was this Duty to Care Breached, is there
      negative Consequences as a result? <em>ACM Code</em>: Act according to ACM
      Code.
    </p>
    <h3 id="consent">Consent</h3>
    <ol>
      <li>Capacity (ability to cognitively make a decision)</li>
      <li>Information (informed)</li>
    </ol>
    <h3 id="dignity">Dignity</h3>
    <p>
      Your Code derives dignity, not from Kant but from the
      <strong>Universal Decleration of Human Rights</strong>. However the UDHR
      was written by Hans Kelson who is a Kantian but Kelson also uses
      <em>religious conceptions</em> of dignity and <em>Ancient Rome</em>.
    </p>
    <p>
      (note: Rights and Duties, 2 sides 1 coin - and generally refers to
      Deontology)
    </p>

    <!-- WEEK 4 -->

    <!-- JavaScript Bundle with Popper -->
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-u1OknCvxWvY5kfmNBILK2hRnQC3Pr17a+RTT6rIHI7NnikvbZlHgTPOOmMi466C8"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
