# Summary of Week05 Lecture

### Stakeholder Theory

Used to have Shareholders/Stockholders which are basically owners. However this approach has fallen out of favour, we tend to think of management as "Stakeholders".
Stakeholders can either be _direct_ (e.g End-Users, Employees, Clients, Investors, Suppliers) or _indirect_ (e.g Community, Regulators, Government).

### Comprehensive Moral Responsibility

Milton: only moral responsibility is on shareholders/stockholders.
Stakeholder Theory: all stakeholders have moral responsibility.
Comprehensive Moral Responsibility: impacts from product/service on humanity/environment, i.e. broadening of interest.

### (Article) Responsible Autonomy

Autonomy: self-guidance/_self-governence_
Responsibility: answerable/blameworthy
Responsible Autonomy: connects the notion of autonomous (AI, machines) to notions of moral responsibility.
There is a _need_ for a responsible approach to AI.

- Ethical: how they impact on people/environment
- Legal Consequences: national + state legislation and possibility to extend to _Australian Human Rights Commission_ (search with keyword AI for presentation).

There needs to be a design for tools and methods in order to reflect _human values_ (ACM: primary human value was community wellbeing).

### Freeman's values:

1. Human Welfare
2. Ownership and Property: right to control and dispose pieces of information.
3. Privacy: consent/control over your personal information. Your right to how much people can be informed upon your life.
4. Freedom from bias: eliminating unfairness as a result from your membership of a certain group.
5. Universal Usability: (connection to freedom from bias), how to permit and include people with disabilities/financially worse off with technology.
6. Trust: people need to be able to trust the products/services they use.
7. Autonomy: refering to the human capacity to choose for itself. (Autocratic - tells you what to decide, limits user's choice for action)
8. Informed Consent: fully aware what you are permitting, whilst having certain capacities (e.g over 12/13).
9. Accountability: accountability party is the party that is ultimately accountability (aside from responsibility - e.g. managing construction worker who hurt themselves, you are accountability for their training).
10. Courtesy
11. Identity: respect people's identity (e.g. gender-neutral language, cannot assume financial status/class-identity, racial etc.), assume diversity: requires research on the diversity of the community the product/service wishes to cater to.
12. Calmness: refering to not agitating users needlessly.
13. Environmental: environmental sustainability.

### Ethical/Legal Consequences (cont...)

Safe + Beneficial (e.g. Welfare, Universal Usability, eliminate bias, Privacy could be at stake).
Morally relevant decision making (some moral theories are seen better suited for certain situations), e.g. healthcare software: consequentialist moral theory will predominate.
The type of moral thinking the artifical entity should be engaged depends on the context they are shaped/used in.
